{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 深度卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 端到端\n",
    "\n",
    "神经网络可以直接基于图像的原始像素进行分类，这种方法称为端到端（end-to-end）。\n",
    "\n",
    "但是LeNet提出后的，我们依然还是用svm等机器学习来进行分类，并且效果不错。\n",
    "    \n",
    "    1、获取图像数据集；\n",
    "    2、使用已有的特征提取函数生成图像的特征；\n",
    "    3、使用机器学习模型对图像的特征分类。\n",
    "\n",
    "但是神经网络派认为，特征也是可以学习的，而不需要人工去提取。不过由于数据缺乏和硬件计算能力不行，倒是深层的神经网络效果不行。\n",
    "\n",
    "直到2012年的AlexNet。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AlexNet的模型结构\n",
    "\n",
    "    AlexNet与LeNet的设计理念非常相似，但也有显著的区别。\n",
    "\n",
    "    第一，与相对较小的LeNet相比，AlexNet包含8层变换，其中有5层卷积和2层全连接隐藏层，以及1个全连接输出层。下面我们来详细描述这些层的设计。\n",
    "\n",
    "    AlexNet第一层中的卷积窗口形状是11×11。因为ImageNet中绝大多数图像的高和宽均比MNIST图像的高和宽大10倍以上，ImageNet图像的物体占用更多的像素，所以需要更大的卷积窗口来捕获物体。第二层中的卷积窗口形状减小到5×5，之后全采用3×3。此外，第一、第二和第五个卷积层之后都使用了窗口形状为3×3、步幅为2的最大池化层。而且，AlexNet使用的卷积通道数也大于LeNet中的卷积通道数数十倍。\n",
    "\n",
    "    紧接着最后一个卷积层的是两个输出个数为4096的全连接层。这两个巨大的全连接层带来将近1 GB的模型参数。由于早期显存的限制，最早的AlexNet使用双数据流的设计使一个GPU只需要处理一半模型。幸运的是，显存在过去几年得到了长足的发展，因此通常我们不再需要这样的特别设计了。\n",
    "\n",
    "    第二，AlexNet将sigmoid激活函数改成了更加简单的ReLU激活函数。一方面，ReLU激活函数的计算更简单，例如它并没有sigmoid激活函数中的求幂运算。另一方面，ReLU激活函数在不同的参数初始化方法下使模型更容易训练。这是由于当sigmoid激活函数输出极接近0或1时，这些区域的梯度几乎为0，从而造成反向传播无法继续更新部分模型参数；而ReLU激活函数在正区间的梯度恒为1。因此，若模型参数初始化不当，sigmoid函数可能在正区间得到几乎为0的梯度，从而令模型无法得到有效训练。\n",
    "\n",
    "    第三，AlexNet通过丢弃法（dropout）来控制全连接层的模型复杂度。而LeNet并没有使用丢弃法。\n",
    "\n",
    "    第四，AlexNet引入了大量的图像增广，如翻转、裁剪和颜色变化，从而进一步扩大数据集来缓解过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据\n",
    "\n",
    "    虽然论文中AlexNet使用ImageNet数据集，但因为ImageNet数据集训练时间较长，我们仍用前面的Fashion-MNIST数据集来演示AlexNet。读取数据的时候我们额外做了一步将图像高和宽扩大到AlexNet使用的图像高和宽224。这个可以通过Resize实例来实现。也就是说，我们在ToTensor实例前使用Resize实例，然后使用Compose实例来将这两个变换串联以方便调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AlexNet实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#  basic package\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D,Flatten,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入数据\n",
    "# fashion-mnist\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "X_train, y_train = load_mnist('F:/机器学习/动手学深度学习/data/fashion', kind='train')\n",
    "X_test, y_test = load_mnist('F:/机器学习/动手学深度学习/data/fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_resize(input, new_width, new_height):\n",
    "    \"\"\"\n",
    "        imput:  ndarray\n",
    "        return: ndarray\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    img = Image.fromarray(input)\n",
    "    new_img = img.resize((new_width, new_height),Image.ADAPTIVE)\n",
    "    return np.array(new_img)\n",
    "\n",
    "def show_imgage(im2):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(im2)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784,), array([60000,   224,   224]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape,np.array((X_train.shape[0], 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 759 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 处理数据\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "sample_size = 1000\n",
    "\n",
    "X_train_new = np.zeros([sample_size, 224, 224])\n",
    "\n",
    "# 填充28 -224\n",
    "for i in range(sample_size):\n",
    "    X_train_new[i] = image_resize(X_train[i].reshape(28,28), 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 575 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_1 = X_train_new / 255\n",
    "x_train = X_train_1.reshape(-1, 224, 224, 1)\n",
    "\n",
    "X_test_new = np.zeros([sample_size, 224, 224])\n",
    "X_test_1 = X_test_new / 255\n",
    "x_test = X_test_1.reshape(-1, 224, 224, 1)\n",
    "\n",
    "y_train = to_categorical(y_train[:sample_size], num_classes=10)\n",
    "y_test = to_categorical(y_test[:sample_size], num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 224, 224, 1), (1000, 224, 224, 1), (1000, 10), (1000, 10))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 205 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 定义模型keras\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "model = Sequential([\n",
    "    # part 1\n",
    "    Conv2D(filters=96, kernel_size=(11, 11), activation='relu', strides=(4,4), padding='valid', input_shape=(224, 224, 1)), \n",
    "    MaxPooling2D(pool_size=(3, 3), strides=(2,2), padding='valid'),\n",
    "    Conv2D(filters=256, kernel_size=(5, 5), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(3, 3), strides=(2,2), padding='valid'),\n",
    "    \n",
    "    # part 2\n",
    "    # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。\n",
    "    # 前两个卷积层后不使用池化层来减小输入的高和宽\n",
    "    Conv2D(filters=384, kernel_size=(3, 3), padding=\"same\", activation='relu'),\n",
    "    Conv2D(filters=384, kernel_size=(3, 3), padding=\"same\", activation='relu'),\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation='relu'),\n",
    "    MaxPooling2D(pool_size=(3, 3), strides=(2,2), padding='valid'),\n",
    "    \n",
    "    Flatten(),\n",
    "    # 全连接层块\n",
    "    Dense(4096,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# compile\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# conv0 output shape:      (1, 96, 54, 54)\n",
    "# pool0 output shape:      (1, 96, 26, 26)\n",
    "# conv1 output shape:      (1, 256, 26, 26)\n",
    "# pool1 output shape:      (1, 256, 12, 12)\n",
    "# conv2 output shape:      (1, 384, 12, 12)\n",
    "# conv3 output shape:      (1, 384, 12, 12)\n",
    "# conv4 output shape:      (1, 256, 12, 12)\n",
    "# pool2 output shape:      (1, 256, 5, 5)\n",
    "# dense0 output shape:     (1, 4096)\n",
    "# dropout0 output shape:   (1, 4096)\n",
    "# dense1 output shape:     (1, 4096)\n",
    "# dropout1 output shape:   (1, 4096)\n",
    "# dense2 output shape:     (1, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 54, 54, 96)        11712     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 26, 26, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              26218496  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 46,764,746\n",
      "Trainable params: 46,764,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "# for layer in model.layers:\n",
    "#     print(layer.output_shape)\n",
    "# for i in range(len(model.layers)):\n",
    "#     print(model.get_layer(index=i).output)\n",
    "\n",
    "# print(\"[INFO] Method 2...\")\n",
    "# for i in range(len(model.layers)):\n",
    "#     print(model.get_layer(index=i).output)\n",
    "\n",
    "# print(\"[INFO] Method 3...\")\n",
    "# for layer in model.layers:\n",
    "#     print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 2.2979 - acc: 0.1270\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 2.2802 - acc: 0.2220\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 2.2197 - acc: 0.2580\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 1.8851 - acc: 0.3290\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 1.5763 - acc: 0.4090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea33151dd8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 4s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "loss_and_metric = model.evaluate(x_test, y_test, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.3044380016326906, 0.087]\n"
     ]
    }
   ],
   "source": [
    "print(loss_and_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
