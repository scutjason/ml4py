{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、优化与深度学习\n",
    "\n",
    "#### 局部最小值\n",
    "\n",
    "对于目标函数f(x)，如果f(x)在x上的值比在x邻近的其他点的值更小，那么f(x)可能是一个局部最小值（local minimum）。如果f(x)在x上的值是目标函数在整个定义域上的最小值，那么f(x)是全局最小值（global minimum）。\n",
    "\n",
    "#### 鞍点\n",
    "\n",
    "刚刚我们提到，梯度接近或变成零可能是由于当前解在局部最优解附近造成的。事实上，另一种可能性是当前解在鞍点（saddle point）附近。\n",
    "<img src=\"img/chapter_optimization_optimization-intro_5_0.svg\">\n",
    "\n",
    "假设一个函数的输入为k维向量，输出为标量，那么它的海森矩阵（Hessian matrix）有k个特征值。该函数在梯度为0的位置上可能是局部最小值、局部最大值或者鞍点。\n",
    "\n",
    "    当函数的海森矩阵在梯度为零的位置上的特征值全为正时，该函数得到局部最小值。\n",
    "    当函数的海森矩阵在梯度为零的位置上的特征值全为负时，该函数得到局部最大值。\n",
    "    当函数的海森矩阵在梯度为零的位置上的特征值有正有负时，该函数得到鞍点。\n",
    "\n",
    "随机矩阵理论告诉我们，对于一个大的高斯随机矩阵来说，任一特征值是正或者是负的概率都是0.5 [1]。那么，以上第一种情况的概率为 0.5k。由于深度学习模型参数通常都是高维的（k很大），目标函数的鞍点通常比局部最小值更常见。\n",
    "\n",
    "在深度学习中，虽然找到目标函数的全局最优解很难，但这并非必要。我们将在本章接下来的几节中逐一介绍深度学习中常用的优化算法，它们在很多实际问题中都能够训练出十分有效的深度学习模型。\n",
    "\n",
    "#### 小结\n",
    "\n",
    "    由于优化算法的目标函数通常是一个基于训练数据集的损失函数，优化的目标在于降低训练误差。\n",
    "    由于深度学习模型参数通常都是高维的，目标函数的鞍点通常比局部最小值更常见。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
