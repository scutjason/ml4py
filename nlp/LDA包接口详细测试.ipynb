{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamulticore import LdaMulticore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、Dictionary\n",
    "\n",
    "    将doc转成Dictionary字典 (id, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [\"Human machine interface for lab abc computer applications\".split(),\n",
    "             \"A survey of user opinion of computer system response time\".split(),\n",
    "             \"The EPS user interface management system\".split(),\n",
    "             \"System and human system engineering testing of EPS\".split(),\n",
    "             \"Relation of user perceived response time to error measurement\".split(),\n",
    "             \"The generation of random binary unordered trees\".split(),\n",
    "             \"The intersection graph of paths in trees\".split(),\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\".split(),\n",
    "             \"Graph minors A survey\".split()]\n",
    "\n",
    "dictionary = Dictionary(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 'Human', gensim.corpora.dictionary.Dictionary)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary),dictionary[0],type(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    return_missing参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], {'big': 1, 'bryant': 1, 'is': 2, 'this': 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc=[\"this\",\"is\",\"bryant\", \"is\", \"big\"]\n",
    "#       return_missing : bool, optional\n",
    "#             Also return missing tokens (that doesn't contains in current dictionary).\n",
    "dictionary.doc2bow(new_doc, return_missing=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 'Human', gensim.corpora.dictionary.Dictionary)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary),dictionary[0],type(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    allow_update参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(20, 1), (45, 1), (46, 1), (47, 1), (48, 2), (49, 1), (50, 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc=[\"my\",\"son\", \"is\", \"bryant\", \"and\", \"he\", \"is\", \"exelent\"]\n",
    "#         allow_update : bool, optional \n",
    "#             If True - update dictionary in the process (i.e. add new tokens and update frequencies).\n",
    "dictionary.doc2bow(new_doc, allow_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 'Human', gensim.corpora.dictionary.Dictionary)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary),dictionary[0],type(dictionary)   # 更新了6个token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    doc2idx 返回doc的id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49, 50, 48, 45, 20, 47, 48, -1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc=[\"my\",\"son\", \"is\", \"bryant\", \"and\", \"he\", \"is\", \"bravo\"]\n",
    "dictionary.doc2idx(new_doc)   ### 不在词表中，返回-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    token2id : dict of (str, int) 字段\n",
    "        token -> tokenId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 8,\n",
       " 'EPS': 16,\n",
       " 'Graph': 38,\n",
       " 'Human': 0,\n",
       " 'IV': 39,\n",
       " 'Relation': 24,\n",
       " 'System': 19,\n",
       " 'The': 17,\n",
       " 'Widths': 40,\n",
       " 'abc': 1,\n",
       " 'and': 20,\n",
       " 'applications': 2,\n",
       " 'binary': 29,\n",
       " 'bryant': 45,\n",
       " 'computer': 3,\n",
       " 'engineering': 21,\n",
       " 'error': 25,\n",
       " 'exelent': 46,\n",
       " 'for': 4,\n",
       " 'generation': 30,\n",
       " 'graph': 34,\n",
       " 'he': 47,\n",
       " 'human': 22,\n",
       " 'in': 35,\n",
       " 'interface': 5,\n",
       " 'intersection': 36,\n",
       " 'is': 48,\n",
       " 'lab': 6,\n",
       " 'machine': 7,\n",
       " 'management': 18,\n",
       " 'measurement': 26,\n",
       " 'minors': 41,\n",
       " 'my': 49,\n",
       " 'of': 9,\n",
       " 'opinion': 10,\n",
       " 'ordering': 42,\n",
       " 'paths': 37,\n",
       " 'perceived': 27,\n",
       " 'quasi': 43,\n",
       " 'random': 31,\n",
       " 'response': 11,\n",
       " 'son': 50,\n",
       " 'survey': 12,\n",
       " 'system': 13,\n",
       " 'testing': 23,\n",
       " 'time': 14,\n",
       " 'to': 28,\n",
       " 'trees': 32,\n",
       " 'unordered': 33,\n",
       " 'user': 15,\n",
       " 'well': 44}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    dfs字段  dict of (int, int)\n",
    "        Document frequencies: token_id -> in how many documents contain this token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1,\n",
       " 1: 1,\n",
       " 2: 1,\n",
       " 3: 2,\n",
       " 4: 1,\n",
       " 5: 2,\n",
       " 6: 1,\n",
       " 7: 1,\n",
       " 8: 2,\n",
       " 9: 6,\n",
       " 10: 1,\n",
       " 11: 2,\n",
       " 12: 2,\n",
       " 13: 3,\n",
       " 14: 2,\n",
       " 15: 3,\n",
       " 16: 2,\n",
       " 17: 3,\n",
       " 18: 1,\n",
       " 19: 1,\n",
       " 20: 3,\n",
       " 21: 1,\n",
       " 22: 1,\n",
       " 23: 1,\n",
       " 24: 1,\n",
       " 25: 1,\n",
       " 26: 1,\n",
       " 27: 1,\n",
       " 28: 1,\n",
       " 29: 1,\n",
       " 30: 1,\n",
       " 31: 1,\n",
       " 32: 3,\n",
       " 33: 1,\n",
       " 34: 1,\n",
       " 35: 1,\n",
       " 36: 1,\n",
       " 37: 1,\n",
       " 38: 2,\n",
       " 39: 1,\n",
       " 40: 1,\n",
       " 41: 2,\n",
       " 42: 1,\n",
       " 43: 1,\n",
       " 44: 1,\n",
       " 45: 1,\n",
       " 46: 1,\n",
       " 47: 1,\n",
       " 48: 1,\n",
       " 49: 1,\n",
       " 50: 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     num_docs : int   一共有多少文档\n",
    "        Number of documents processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.num_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       merge_with： 合并两个Dictionary\n",
    "          Merge another dictionary into this dictionary, mapping same tokens to the same ids and new tokens to new ids.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0, 'b': 1, 'c': 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_1, corpus_2 = [[\"a\", \"b\", \"c\"]], [[\"a\", \"f\", \"f\"]]\n",
    "dct_1, dct_2 = Dictionary(corpus_1), Dictionary(corpus_2)\n",
    "dct_1.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0, 'b': 1, 'c': 2, 'f': 3}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = dct_1.merge_with(dct_2)\n",
    "dct_1.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    filter_extremes 接口\n",
    "    \n",
    "        no_below : int, optional   至少有几篇doc包含每个token。 len(all_docs) * 5% 吧\n",
    "            Keep tokens which are contained in at least `no_below` documents.\n",
    "            \n",
    "        no_above : float, optional   其实就是len(doc_contain_token) / len(all_docs) <= no_above\n",
    "            Keep tokens which are contained in no more than `no_above` documents  \n",
    "            (fraction of total corpus size, not an absolute number).\n",
    "            \n",
    "        keep_n : int, optional  默认是10w\n",
    "            Keep only the first `keep_n` most frequent tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [[\"hello\", \"you\", \"are\"], [\"are\", \"big\", \"me\"],['hello','she'],['hello','it']]\n",
    "dct = Dictionary(corpus)\n",
    "len(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "are\n",
      "you\n",
      "big\n",
      "me\n",
      "she\n",
      "it\n"
     ]
    }
   ],
   "source": [
    "dct.filter_extremes(no_below=1, no_above=0.5, keep_n=100)\n",
    "print(len(dct))\n",
    "for i in dct:\n",
    "    print(dct[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    cfs Document frequencies: token_id -> how many documents contain this token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of:\t\t\t 7\n",
      "user:\t\t\t 3\n",
      "system:\t\t\t 3\n",
      "The:\t\t\t 3\n",
      "and:\t\t\t 3\n",
      "trees:\t\t\t 3\n",
      "interface:\t\t\t 2\n",
      "computer:\t\t\t 2\n",
      "A:\t\t\t 2\n",
      "survey:\t\t\t 2\n",
      "response:\t\t\t 2\n",
      "time:\t\t\t 2\n",
      "EPS:\t\t\t 2\n",
      "Graph:\t\t\t 2\n",
      "minors:\t\t\t 2\n",
      "is:\t\t\t 2\n",
      "Human:\t\t\t 1\n",
      "machine:\t\t\t 1\n",
      "for:\t\t\t 1\n",
      "lab:\t\t\t 1\n",
      "abc:\t\t\t 1\n",
      "applications:\t\t\t 1\n",
      "opinion:\t\t\t 1\n",
      "management:\t\t\t 1\n",
      "System:\t\t\t 1\n",
      "human:\t\t\t 1\n",
      "engineering:\t\t\t 1\n",
      "testing:\t\t\t 1\n",
      "Relation:\t\t\t 1\n",
      "perceived:\t\t\t 1\n",
      "to:\t\t\t 1\n",
      "error:\t\t\t 1\n",
      "measurement:\t\t\t 1\n",
      "generation:\t\t\t 1\n",
      "random:\t\t\t 1\n",
      "binary:\t\t\t 1\n",
      "unordered:\t\t\t 1\n",
      "intersection:\t\t\t 1\n",
      "graph:\t\t\t 1\n",
      "paths:\t\t\t 1\n",
      "in:\t\t\t 1\n",
      "IV:\t\t\t 1\n",
      "Widths:\t\t\t 1\n",
      "well:\t\t\t 1\n",
      "quasi:\t\t\t 1\n",
      "ordering:\t\t\t 1\n",
      "my:\t\t\t 1\n",
      "son:\t\t\t 1\n",
      "bryant:\t\t\t 1\n",
      "he:\t\t\t 1\n",
      "exelent:\t\t\t 1\n"
     ]
    }
   ],
   "source": [
    "id_freq = sorted(dictionary.cfs.items(),key=lambda x:x[1], reverse=True)\n",
    "# print(id_freq)\n",
    "for i in id_freq:\n",
    "    print(dictionary.id2token[i[0]] + \":\\t\\t\\t\", i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、corpus\n",
    "        \n",
    "        实际上就是把每篇文档结合字典Dictionary变成，doc_1 = [(id,freq),(id,freq)...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(3, 1),\n",
       "  (8, 1),\n",
       "  (9, 2),\n",
       "  (10, 1),\n",
       "  (11, 1),\n",
       "  (12, 1),\n",
       "  (13, 1),\n",
       "  (14, 1),\n",
       "  (15, 1)],\n",
       " [(5, 1), (13, 1), (15, 1), (16, 1), (17, 1), (18, 1)],\n",
       " [(9, 1), (13, 1), (16, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1)],\n",
       " [(9, 1),\n",
       "  (11, 1),\n",
       "  (14, 1),\n",
       "  (15, 1),\n",
       "  (24, 1),\n",
       "  (25, 1),\n",
       "  (26, 1),\n",
       "  (27, 1),\n",
       "  (28, 1)],\n",
       " [(9, 1), (17, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1)],\n",
       " [(9, 1), (17, 1), (32, 1), (34, 1), (35, 1), (36, 1), (37, 1)],\n",
       " [(9, 1),\n",
       "  (20, 1),\n",
       "  (32, 1),\n",
       "  (38, 1),\n",
       "  (39, 1),\n",
       "  (40, 1),\n",
       "  (41, 1),\n",
       "  (42, 1),\n",
       "  (43, 1),\n",
       "  (44, 1)],\n",
       " [(8, 1), (12, 1), (38, 1), (41, 1)]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('computer', 1),\n",
       "  ('A', 1),\n",
       "  ('of', 2),\n",
       "  ('opinion', 1),\n",
       "  ('response', 1),\n",
       "  ('survey', 1),\n",
       "  ('system', 1),\n",
       "  ('time', 1),\n",
       "  ('user', 1)]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(dictionary.id2token[id], freq) for id, freq in cp] for cp in corpus[1:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 问：如果doc中不存在某个word呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=1, no_above=0.5, keep_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 2,\n",
       " 'The': 7,\n",
       " 'and': 8,\n",
       " 'computer': 0,\n",
       " 'interface': 1,\n",
       " 'response': 3,\n",
       " 'survey': 4,\n",
       " 'system': 5,\n",
       " 'trees': 9,\n",
       " 'user': 6}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in documents]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1)],\n",
       " [(0, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)],\n",
       " [(1, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(5, 1), (8, 1)],\n",
       " [(3, 1), (6, 1)],\n",
       " [(7, 1), (9, 1)],\n",
       " [(7, 1), (9, 1)],\n",
       " [(8, 1), (9, 1)],\n",
       " [(2, 1), (4, 1)]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 此时不存在词表dictionary中的token是不会存在corpus中的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3、训练接口\n",
    "\n",
    "    LdaModel  Train and use Online Latent Dirichlet Allocation (OLDA) models  用在线变分贝叶斯推断法求解\n",
    "    \n",
    "        chunksize :  int, optional  2000\n",
    "            Number of documents to be used in each training chunk.  每次训练时的doc数目，类似于batch_size,一次性给入2000篇文章，一次性给入越多，性能越好，该指标会略微影响最终结果\n",
    "            \n",
    "        passes : int, optional     1\n",
    "            Number of passes through the corpus during training.   遍历整个corpus的迭代数，类似于epoch\n",
    "        \n",
    "        alpha : {numpy.ndarray, str}, optional    文档-主题DIR分布的超参\n",
    "            Can be set to an 1D array of length equal to the number of expected topics that expresses\n",
    "            our a-priori belief for the each topics' probability.\n",
    "            Alternatively default prior selecting strategies can be employed by supplying a string:\n",
    "\n",
    "                * 'asymmetric': Uses a fixed normalized asymmetric prior of `1.0 / topicno`.\n",
    "                * 'auto': Learns an asymmetric prior from the corpus (not available if `distributed==True`).\n",
    "    \n",
    "        eta : {float, np.array, str}, optional    主题-词DIR分布的超参\n",
    "            A-priori belief on word probability, this can be:\n",
    "\n",
    "                * scalar for a symmetric prior over topic/word probability,\n",
    "                * vector of length num_words to denote an asymmetric user defined probability for each word,\n",
    "                * matrix of shape (num_topics, num_words) to assign a probability for each word-topic combination,\n",
    "                * the string 'auto' to learn the asymmetric prior from the data.\n",
    "        \n",
    "        iterations : int, optional            做推断时，最大迭代次数\n",
    "            Maximum number of iterations through the corpus when inferring the topic distribution of a corpus.\n",
    "            \n",
    "    LdaMulticore An optimized implementation of the LDA algorithm, able to harness the power of multicore CPUs. LdaModel的多核版本\n",
    "    \n",
    "    \n",
    "Model perplexity and topic coherence provide a convenient measure to judge how good a given topic model is.\n",
    "\n",
    "\n",
    "In my experience, topic coherence score, in particular, has been more helpful.   从经验上看，主题一致性的评价指标更有用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4、pyLDAvis\n",
    "\n",
    "        So how to infer pyLDAvis’s output?   \n",
    "        \n",
    "        Each bubble on the left-hand side plot represents a topic. The larger the bubble, the more prevalent is that topic.\n",
    "        左边的圈圈越大，表示主题内部越相关\n",
    "\n",
    "        A good topic model will have fairly big, non-overlapping bubbles scattered throughout the chart instead of being clustered in one quadrant. 好的模型结果应该是圈圈之间尽可能不重叠，且很大\n",
    "\n",
    "        A model with too many topics, will typically have many overlaps, small sized bubbles clustered in one region of the chart.\n",
    "\n",
    "        Alright, if you move the cursor over one of the bubbles, the words and bars on the right-hand side will update. These words are the salient keywords that form the selected topic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
